# 🧠 Innosign – Bridging Communication for the Speech and Hearing Impaired

**Innosign** is an AI-powered real-time sign language translator that facilitates seamless communication between the speech- and hearing-impaired and the rest of the world. It uses deep learning and computer vision to recognize gestures from **Indian Sign Language (ISL)** and convert them into **text and speech**.

---

## 🚀 Features

- Real-time ISL gesture recognition via webcam
- Converts gestures to text and speech using gTTS
- Speech-to-text input for reverse communication
- End-to-end gesture-to-speech translation system
- Simple desktop/web interface

---

## 🏆 Achievements

- ✅ Selected for the **Smart India Hackathon (SIH)** – a prestigious national innovation event  
- 🥇 Winner of multiple **National-Level Project Expos**  
- ⚙️ Demonstrated a working **end-to-end real-time prototype**  
- 🧩 Recognized for addressing a major accessibility challenge using deep tech

---

## ❗ Problem Statement

Millions of individuals with speech and hearing impairments face communication barriers due to low public awareness of sign language. This restricts access to education, employment, healthcare, and essential services.

**Innosign** bridges this communication gap by:

- Recognizing ISL gestures using computer vision  
- Translating them into natural language text and speech  
- Enabling reverse interaction using speech-to-text  
- Empowering inclusive, two-way communication

---

## 🛠️ Technologies Used

- **Language:** Python 3.8+  
- **Frameworks:** TensorFlow / PyTorch  
- **Vision:** OpenCV, MediaPipe (for hand tracking)  
- **Speech:** gTTS (Google Text-to-Speech), SpeechRecognition  
- **Model:** CNN + LSTM for temporal gesture recognition  
- **Frontend:** Streamlit / Flask (optional)  
- **Target Platforms:** Desktop, Web (Mobile support planned)

---


## ⚙️ Setup Instructions

### 1. Clone the Repository

```bash ```
git clone https://github.com/your-username/innosign.git
cd innosign

### 2. Install Dependencies

Make sure you have Python 3.8+ and pip installed.
```bash```
pip install -r requirements.txt

### 3. Run the Application

```bash```
python code/app.py


---

## DEMO

LINK: https://goto.freeconvert.com/6874d207fd18e268684ffbcf

---

## Future Enhancements

-Expand ISL dataset to include sentence-level and contextual gestures
-Optimize for mobile devices using TensorFlow Lite / MediaPipe mobile SDK
-Integrate avatar-based sign language playback
-Add multilingual support (Hindi, Telugu, Tamil, etc.)
-Deploy on the cloud with a user-friendly web interface

---

## CONTACT

For queries, collaboration, or demo requests:
📧 Email: swathi2004sivakumar@gmail.com
🔗 LinkedIn: linkedin.com/in/swathisivakumar








